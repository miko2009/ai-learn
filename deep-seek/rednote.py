import os

from dotenv import load_dotenv
from openai import OpenAI
from openai.types.chat import ChatCompletionSystemMessageParam, ChatCompletionUserMessageParam
from pymilvus import MilvusClient
import pymilvus.model as pymilvus_model
from glob import glob
from tqdm import tqdm
import random
import time
import re

load_dotenv(verbose=True)
collection_name = "rednote_rag_collection"
import json
TOOLS_DEFINITION = [
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "æœç´¢äº’è”ç½‘ä¸Šçš„å®æ—¶ä¿¡æ¯ï¼Œç”¨äºè·å–æœ€æ–°æ–°é—»ã€æµè¡Œè¶‹åŠ¿ã€ç”¨æˆ·è¯„ä»·ã€è¡Œä¸šæŠ¥å‘Šç­‰ã€‚è¯·ç¡®ä¿æœç´¢å…³é”®è¯ç²¾ç¡®ï¼Œé¿å…å®½æ³›çš„æŸ¥è¯¢ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "è¦æœç´¢çš„å…³é”®è¯æˆ–é—®é¢˜ï¼Œä¾‹å¦‚'æœ€æ–°å°çº¢ä¹¦ç¾å¦†è¶‹åŠ¿'æˆ–'æ·±æµ·è“è—»ä¿æ¹¿é¢è†œ ç”¨æˆ·è¯„ä»·'"
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "query_product_database",
            "description": "æŸ¥è¯¢å†…éƒ¨äº§å“æ•°æ®åº“ï¼Œè·å–æŒ‡å®šäº§å“çš„è¯¦ç»†å–ç‚¹ã€æˆåˆ†ã€é€‚ç”¨äººç¾¤ã€ä½¿ç”¨æ–¹æ³•ç­‰ä¿¡æ¯ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "product_name": {
                        "type": "string",
                        "description": "è¦æŸ¥è¯¢çš„äº§å“åç§°ï¼Œä¾‹å¦‚'æ·±æµ·è“è—»ä¿æ¹¿é¢è†œ'"
                    }
                },
                "required": ["product_name"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "generate_emoji",
            "description": "æ ¹æ®æä¾›çš„æ–‡æœ¬å†…å®¹ï¼Œç”Ÿæˆä¸€ç»„é€‚åˆå°çº¢ä¹¦é£æ ¼çš„è¡¨æƒ…ç¬¦å·ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "context": {
                        "type": "string",
                        "description": "æ–‡æ¡ˆçš„å…³é”®å†…å®¹æˆ–æƒ…æ„Ÿï¼Œä¾‹å¦‚'æƒŠå–œæ•ˆæœ'ã€'è¡¥æ°´ä¿æ¹¿'"
                    }
                },
                "required": ["context"]
            }
        }
    }
]
def generate_rednote(product_name: str, tone_style: str = "æ´»æ³¼ç”œç¾", max_iterations: int = 5, available_tools: list[dict] = []) -> str:
    """
    ä½¿ç”¨ DeepSeek Agent ç”Ÿæˆå°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆã€‚

    Args:
        product_name (str): è¦ç”Ÿæˆæ–‡æ¡ˆçš„äº§å“åç§°ã€‚
        tone_style (str): æ–‡æ¡ˆçš„è¯­æ°”å’Œé£æ ¼ï¼Œå¦‚"æ´»æ³¼ç”œç¾"ã€"çŸ¥æ€§"ã€"ææ€ª"ç­‰ã€‚
        max_iterations (int): Agent æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯ã€‚
        available_tools(list): å·¥å…·é›†åˆ

    Returns:
        str: ç”Ÿæˆçš„çˆ†æ¬¾æ–‡æ¡ˆï¼ˆJSON æ ¼å¼å­—ç¬¦ä¸²ï¼‰ã€‚
    """
    SYSTEM_PROMPT = """
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆä¸“å®¶ï¼Œæ“…é•¿ç»“åˆæœ€æ–°æ½®æµå’Œäº§å“å–ç‚¹ï¼Œåˆ›ä½œå¼•äººå…¥èƒœã€é«˜äº’åŠ¨ã€é«˜è½¬åŒ–çš„ç¬”è®°æ–‡æ¡ˆã€‚

    ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„äº§å“å’Œéœ€æ±‚ï¼Œç”ŸæˆåŒ…å«æ ‡é¢˜ã€æ­£æ–‡ã€ç›¸å…³æ ‡ç­¾å’Œè¡¨æƒ…ç¬¦å·çš„å®Œæ•´å°çº¢ä¹¦ç¬”è®°ã€‚

    è¯·å§‹ç»ˆé‡‡ç”¨'Thought-Action-Observation'æ¨¡å¼è¿›è¡Œæ¨ç†å’Œè¡ŒåŠ¨ã€‚æ–‡æ¡ˆé£æ ¼éœ€æ´»æ³¼ã€çœŸè¯šã€å¯Œæœ‰æ„ŸæŸ“åŠ›ã€‚å½“å®Œæˆä»»åŠ¡åï¼Œè¯·ä»¥JSONæ ¼å¼ç›´æ¥è¾“å‡ºæœ€ç»ˆæ–‡æ¡ˆï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    ```json
    {
      "title": "å°çº¢ä¹¦æ ‡é¢˜",
      "body": "å°çº¢ä¹¦æ­£æ–‡",
      "hashtags": ["#æ ‡ç­¾1", "#æ ‡ç­¾2", "#æ ‡ç­¾3", "#æ ‡ç­¾4", "#æ ‡ç­¾5"],
      "emojis": ["âœ¨", "ğŸ”¥", "ğŸ’–"]
    }
    ```
    åœ¨ç”Ÿæˆæ–‡æ¡ˆå‰ï¼Œè¯·åŠ¡å¿…å…ˆæ€è€ƒå¹¶æ”¶é›†è¶³å¤Ÿçš„ä¿¡æ¯ã€‚
    """
    print(f"\nğŸš€ å¯åŠ¨å°çº¢ä¹¦æ–‡æ¡ˆç”ŸæˆåŠ©æ‰‹ï¼Œäº§å“ï¼š{product_name}ï¼Œé£æ ¼ï¼š{tone_style}\n")
    USER_PROMPT = f"è¯·ä¸ºäº§å“ã€Œ{product_name}ã€ç”Ÿæˆä¸€ç¯‡å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆã€‚è¦æ±‚ï¼šè¯­æ°”{tone_style}ï¼ŒåŒ…å«æ ‡é¢˜ã€æ­£æ–‡ã€è‡³å°‘5ä¸ªç›¸å…³æ ‡ç­¾å’Œ5ä¸ªè¡¨æƒ…ç¬¦å·ã€‚è¯·ä»¥å®Œæ•´çš„JSONæ ¼å¼è¾“å‡ºï¼Œå¹¶ç¡®ä¿JSONå†…å®¹ç”¨markdownä»£ç å—åŒ…è£¹ï¼ˆä¾‹å¦‚ï¼š```json{{...}}```ï¼‰ã€‚"
    messages = [
        ChatCompletionSystemMessageParam(role="system", content=SYSTEM_PROMPT),
        ChatCompletionUserMessageParam(role="user", content=USER_PROMPT),
    ]
    iteration_count = 0
    final_response = None
    while iteration_count < max_iterations:
        iteration_count += 1
        print(f"-- Iteration {iteration_count} --")

        try:
            # è°ƒç”¨ DeepSeek APIï¼Œä¼ å…¥å¯¹è¯å†å²å’Œå·¥å…·å®šä¹‰
            response = send_messages(messages,TOOLS_DEFINITION)

            response_message = response.choices[0].message

            # **ReActæ¨¡å¼ï¼šå¤„ç†å·¥å…·è°ƒç”¨**
            if response_message.tool_calls:  # å¦‚æœæ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·
                print("Agent: å†³å®šè°ƒç”¨å·¥å…·...")
                messages.append(response_message)  # å°†å·¥å…·è°ƒç”¨ä¿¡æ¯æ·»åŠ åˆ°å¯¹è¯å†å²

                tool_outputs = []
                for tool_call in response_message.tool_calls:
                    function_name = tool_call.function.name
                    # ç¡®ä¿å‚æ•°æ˜¯åˆæ³•çš„JSONå­—ç¬¦ä¸²ï¼Œå³ä½¿å·¥å…·ä¸è¦æ±‚å‚æ•°ï¼Œä¹Ÿéœ€è¦ä¼ é€’ç©ºå­—å…¸
                    function_args = json.loads(tool_call.function.arguments) if tool_call.function.arguments else {}

                    print(f"Agent Action: è°ƒç”¨å·¥å…· '{function_name}'ï¼Œå‚æ•°ï¼š{function_args}")

                    # æŸ¥æ‰¾å¹¶æ‰§è¡Œå¯¹åº”çš„æ¨¡æ‹Ÿå·¥å…·å‡½æ•°
                    if function_name in available_tools:
                        tool_function = available_tools[function_name]
                        tool_result = tool_function(**function_args)
                        print(f"Observation: å·¥å…·è¿”å›ç»“æœï¼š{tool_result}")
                        tool_outputs.append({
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "content": str(tool_result)  # å·¥å…·ç»“æœä½œä¸ºå­—ç¬¦ä¸²è¿”å›
                        })
                    else:
                        error_message = f"é”™è¯¯ï¼šæœªçŸ¥çš„å·¥å…· '{function_name}'"
                        print(error_message)
                        tool_outputs.append({
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "content": error_message
                        })
                messages.extend(tool_outputs)  # å°†å·¥å…·æ‰§è¡Œç»“æœä½œä¸º Observation æ·»åŠ åˆ°å¯¹è¯å†å²

            # **ReAct æ¨¡å¼ï¼šå¤„ç†æœ€ç»ˆå†…å®¹**
            elif response_message.content:  # å¦‚æœæ¨¡å‹ç›´æ¥è¿”å›å†…å®¹ï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆç­”æ¡ˆï¼‰
                print(f"[æ¨¡å‹ç”Ÿæˆç»“æœ] {response_message.content}")

                # --- START: æ·»åŠ  JSON æå–å’Œè§£æé€»è¾‘ ---
                json_string_match = re.search(r"```json\s*(\{.*\})\s*```", response_message.content, re.DOTALL)

                if json_string_match:
                    extracted_json_content = json_string_match.group(1)
                    try:
                        final_response = json.loads(extracted_json_content)
                        print("Agent: ä»»åŠ¡å®Œæˆï¼ŒæˆåŠŸè§£ææœ€ç»ˆJSONæ–‡æ¡ˆã€‚")
                        return json.dumps(final_response, ensure_ascii=False, indent=2)
                    except json.JSONDecodeError as e:
                        print(f"Agent: æå–åˆ°JSONå—ä½†è§£æå¤±è´¥: {e}")
                        print(f"å°è¯•è§£æçš„å­—ç¬¦ä¸²:\n{extracted_json_content}")
                        messages.append(response_message)  # è§£æå¤±è´¥ï¼Œç»§ç»­å¯¹è¯
                else:
                    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ° ```json å—ï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ª content
                    try:
                        final_response = json.loads(response_message.content)
                        print("Agent: ä»»åŠ¡å®Œæˆï¼Œç›´æ¥è§£ææœ€ç»ˆJSONæ–‡æ¡ˆã€‚")
                        return json.dumps(final_response, ensure_ascii=False, indent=2)
                    except json.JSONDecodeError:
                        print("Agent: ç”Ÿæˆäº†éJSONæ ¼å¼å†…å®¹æˆ–éMarkdown JSONå—ï¼Œå¯èƒ½è¿˜åœ¨æ€è€ƒæˆ–å‡ºé”™ã€‚")
                        messages.append(response_message)  # éJSONæ ¼å¼ï¼Œç»§ç»­å¯¹è¯
                # --- END: æ·»åŠ  JSON æå–å’Œè§£æé€»è¾‘ ---
            else:
                print("Agent: æœªçŸ¥å“åº”ï¼Œå¯èƒ½éœ€è¦æ›´å¤šäº¤äº’ã€‚")
                break

        except Exception as e:
            print(f"è°ƒç”¨ DeepSeek API æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            break

    print("\nâš ï¸ Agent è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æˆ–æœªèƒ½ç”Ÿæˆæœ€ç»ˆæ–‡æ¡ˆã€‚è¯·æ£€æŸ¥Promptæˆ–å¢åŠ è¿­ä»£æ¬¡æ•°ã€‚")
    return "æœªèƒ½æˆåŠŸç”Ÿæˆæ–‡æ¡ˆã€‚"

def send_messages(messages, tools):
    deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
    client = OpenAI(api_key=deepseek_api_key, base_url="https://api.deepseek.com/v1")
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=messages,
        tools=tools,
        tool_choice = 'auto'
    )
    return response
def mock_search_web(query: str) -> str:
    """æ¨¡æ‹Ÿç½‘é¡µæœç´¢å·¥å…·ï¼Œè¿”å›é¢„è®¾çš„æœç´¢ç»“æœã€‚"""
    print(f"[Tool Call] æ¨¡æ‹Ÿæœç´¢ç½‘é¡µï¼š{query}")
    time.sleep(1) # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
    if "å°çº¢ä¹¦ç¾å¦†è¶‹åŠ¿" in query:
        return "è¿‘æœŸå°çº¢ä¹¦ç¾å¦†æµè¡Œ'å¤šå·´èƒºç©¿æ­'ã€'æ—©Cæ™šA'æŠ¤è‚¤ç†å¿µã€'ä¼ªç´ é¢œ'å¦†å®¹ï¼Œçƒ­é—¨å…³é”®è¯æœ‰#æ°›å›´æ„Ÿã€#æŠ—è€ã€#å±éšœä¿®å¤ã€‚"
    elif "ä¿æ¹¿é¢è†œ" in query:
        return "å°çº¢ä¹¦ä¿æ¹¿é¢è†œçƒ­é—¨è¯é¢˜ï¼šæ²™æ¼ å¹²çš®æ•‘æ˜Ÿã€ç†¬å¤œæ€¥æ•‘é¢è†œã€æ°´å…‰è‚Œå…»æˆã€‚ç”¨æˆ·ç—›ç‚¹ï¼šå¡ç²‰ã€æ³›çº¢ã€ç´§ç»·æ„Ÿã€‚"
    elif "æ·±æµ·è“è—»ä¿æ¹¿é¢è†œ" in query:
        return "å…³äºæ·±æµ·è“è—»ä¿æ¹¿é¢è†œçš„ç”¨æˆ·è¯„ä»·ï¼šæ™®éåé¦ˆè¡¥æ°´æ•ˆæœå¥½ï¼Œå¸æ”¶å¿«ï¼Œå¯¹æ•æ„Ÿè‚Œå‹å¥½ã€‚æœ‰ç”¨æˆ·æåˆ°ä»·æ ¼ç•¥é«˜ï¼Œä½†æ•ˆæœå€¼å¾—ã€‚"
    else:
        return f"æœªæ‰¾åˆ°å…³äº '{query}' çš„ç‰¹å®šä¿¡æ¯ï¼Œä½†å¸‚åœºåé¦ˆé€šå¸¸å…³æ³¨äº§å“æˆåˆ†ã€åŠŸæ•ˆå’Œç”¨æˆ·ä½“éªŒã€‚"

def mock_generate_emoji(context: str) -> list:
    """æ¨¡æ‹Ÿç”Ÿæˆè¡¨æƒ…ç¬¦å·ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡æä¾›å¸¸ç”¨è¡¨æƒ…ã€‚"""
    print(f"[Tool Call] æ¨¡æ‹Ÿç”Ÿæˆè¡¨æƒ…ç¬¦å·ï¼Œä¸Šä¸‹æ–‡ï¼š{context}")
    time.sleep(0.2) # æ¨¡æ‹Ÿç”Ÿæˆå»¶è¿Ÿ
    if "è¡¥æ°´" in context or "æ°´æ¶¦" in context or "ä¿æ¹¿" in context:
        return ["ğŸ’¦", "ğŸ’§", "ğŸŒŠ", "âœ¨"]
    elif "æƒŠå–œ" in context or "å“‡å¡" in context or "çˆ±äº†" in context:
        return ["ğŸ’–", "ğŸ˜", "ğŸ¤©", "ğŸ’¯"]
    elif "ç†¬å¤œ" in context or "ç–²æƒ«" in context:
        return ["ğŸ˜­", "ğŸ˜®â€ğŸ’¨", "ğŸ˜´", "ğŸ’¡"]
    elif "å¥½ç‰©" in context or "æ¨è" in context:
        return ["âœ…", "ğŸ‘", "â­", "ğŸ›ï¸"]
    else:
        return random.sample(["âœ¨", "ğŸ”¥", "ğŸ’–", "ğŸ’¯", "ğŸ‰", "ğŸ‘", "ğŸ¤©", "ğŸ’§", "ğŸŒ¿"], k=min(5, len(context.split())))
def init_data():
    milvus_client = MilvusClient(uri="./milvus_demo.db")
    if milvus_client.has_collection(collection_name):
        milvus_client.drop_collection(collection_name)
    embedding_model = pymilvus_model.DefaultEmbeddingFunction()
    test_embedding = embedding_model.encode_queries(["This is a test"])[0]
    embedding_dim = len(test_embedding)
    milvus_client.create_collection(
        collection_name=collection_name,
        metric_type="IP",  # å†…ç§¯è·ç¦»
        consistency_level="Strong",
        dimension=embedding_dim,
        # æ”¯æŒçš„å€¼ä¸º (`"Strong"`, `"Session"`, `"Bounded"`, `"Eventually"`)ã€‚æ›´å¤šè¯¦æƒ…è¯·å‚è§ https://milvus.io/docs/consistency.md#Consistency-Levelã€‚
    )

    text_lines = []

    for file_path in glob("./red-product-info.md", recursive=True):
        with open(file_path, "r") as file:
            file_text = file.read()

        text_lines += file_text.split("### ")
        print(text_lines)
    doc_embeddings = embedding_model.encode_documents(text_lines)
    insert_docs = []
    for i, line in enumerate(tqdm(text_lines, desc="Creating embeddings")):
        print(f"{i}i")
        print(f"{line}line")
        if len(line) < 1:
            continue
        insert_docs.append({"id": i, "vector": doc_embeddings[i], "text": line})

    milvus_client.insert(collection_name=collection_name, data=insert_docs)

def search_db(product_name: str):
    milvus_client = MilvusClient(uri="./milvus_demo.db")
    embedding_model = pymilvus_model.DefaultEmbeddingFunction()
    search_res = milvus_client.search(
        collection_name=collection_name,
        data=embedding_model.encode_queries(
            [product_name],
        ),  # å°†é—®é¢˜è½¬æ¢ä¸ºåµŒå…¥å‘é‡
        limit=1,  # è¿”å›å‰3ä¸ªç»“æœ
        search_params={"metric_type": "IP", "params": {}},  # å†…ç§¯è·ç¦»
        output_fields=["text"],  # è¿”å› text å­—æ®µ
    )
    print(search_res)
    retrieved_lines_with_distances = [
        (res["entity"]["text"], res["distance"]) for res in search_res[0]
    ]
    context = "\n".join(
        [line_with_distance[0] for line_with_distance in retrieved_lines_with_distances]
    )
    return context
def main():
    init_data()
    available_tools = {
        "search_web": mock_search_web,
        "query_product_database": search_db,
        "generate_emoji": mock_generate_emoji,
    }
    product_name = "æ·±æµ·è“è—»ä¿æ¹¿é¢è†œ"
    tone_style = "æ´»æ³¼ç”œç¾"
    # search_db(product_name)
    product_result = generate_rednote(product_name, tone_style,5, available_tools)
    print(product_result)





if __name__ == '__main__':
    main()